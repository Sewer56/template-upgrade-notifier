# LLM Configuration for Auto-PR Generation
#
# Use with: template-upgrade-notifier-cli --auto-pr --llm-config-path ./config.toml
#
# Alternatively, set TEMPLATE_UPGRADE_LLM_MODEL environment variable for simple cases.

[llm]
# Provider to use (required)
# Options: "openai", "openrouter", "anthropic", "gemini"
provider = "openai"

# Model name (required, provider-specific)
# Examples:
#   OpenAI: "gpt-4o", "gpt-4-turbo"
#   Anthropic: "claude-sonnet-4-20250514", "claude-3-5-haiku-20241022"
#   OpenRouter: "anthropic/claude-sonnet-4-20250514", "openai/gpt-4o"
#   Gemini: "gemini-1.5-pro", "gemini-1.5-flash"
model = "gpt-4o"

# API key (optional)
# If not set, falls back to provider environment variable:
#   - OPENAI_API_KEY
#   - ANTHROPIC_API_KEY
#   - OPENROUTER_API_KEY
#   - GOOGLE_API_KEY
# api_key = ""

# Custom base URL (optional)
# Useful for proxies or self-hosted endpoints
# base-url = "https://api.openai.com/v1"

# Request timeout in seconds (optional, default: 600)
# timeout-secs = 600
